{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"| Model                            | train_loss | val_loss | test_loss | version |\n|----------------------------------|------------|----------|-----------|---------|\n| Initial                          |     2.0914 |   6.4632 |    1.2512 |      V1 |\n| Initial (normalized)             |     0.1155 |   0.4484 |    4.7467 |       - |\n| Weekday Factor (non-learnable)   |          - |        - |    4.2924 |      V4 |\n| Weekday Factor Model             |     1.7337 |   6.2968 |    1.2501 |      V5 |\n| Fusion Fashion (concat)          |     4.4311 |   2.0399 |    1.4001 |      V9 |\n| Fusion Fashion (add)             |     4.4655 |   2.0404 |    1.5238 |     V10 |\n| Fusion Fashion (product)         |     4.4871 |   2.0026 |    2.6962 |     V11 |","metadata":{}},{"cell_type":"code","source":"# Read data and aggregate into monthly data\n\nimport pandas as pd\n\ntrain_df = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv')\n# columns: date, date_block_num, shop_id, item_id, item_price, item_cnt_day\ntrain_monthly_df = train_df.groupby(['date_block_num','shop_id','item_id']).agg(sale_cnt_month=('item_cnt_day','sum'),price_month=('item_price','mean')).reset_index()\ntrain_monthly_df['shop_item'] = train_monthly_df['shop_id'].astype('string') + '-' + train_monthly_df['item_id'].astype('string')\nshop_item_list = pd.unique(train_monthly_df['shop_item'])\nshop_list = pd.unique(train_monthly_df['shop_id'])\nitem_list = pd.unique(train_monthly_df['item_id'])\n\nprint(\"count of shop_item:\",len(shop_item_list))\nprint('------')\nprint('count of shop_id:', len(shop_list))\nprint('min shop_id:', min(shop_list))\nprint('max shop id:', max(shop_list))\nprint('------')\nprint('count item_id:', len(item_list))\nprint('min item_id:', min(item_list))\nprint('max item id:', max(item_list))\ntrain_monthly_df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the \"sale_cnt sequences\" of each \"shop_item\"\n## get (data_seq_dict)\n\nimport numpy as np\n\ndata_seq_dict = {}\nfor shop_item in shop_item_list:\n    data_seq_dict[shop_item] = [0.0 for i in range(0,34)]\nfor _, row in train_monthly_df.iterrows():\n    data_seq_dict[row['shop_item']][int(row['date_block_num'])] = row['sale_cnt_month']\n    \nprint(len(data_seq_dict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the \"last price\" of each \"shop_item\" as the future price\n## shopitem_price_dict\n\nimport random\n\nshopitem_price_dict = {}  # {shop_item: [avg_price, current_max_date_block_num, cnt]}\n# record price and max date_block_num of each shop_item\nfor _, row in train_monthly_df.iterrows():\n    if row['shop_item'] not in shopitem_price_dict.keys():\n        shopitem_price_dict[row['shop_item']] = [row['price_month'], row['date_block_num'], 1]\n    else:\n        if row['date_block_num'] > shopitem_price_dict[row['shop_item']][1]:\n            shopitem_price_dict[row['shop_item']] = [row['price_month'], row['date_block_num'], 1]\n        if row['date_block_num'] == shopitem_price_dict[row['shop_item']][1]:\n            entry = shopitem_price_dict[row['shop_item']]\n            count = entry[2] + 1\n            price = (entry[0] * entry[2] + row['price_month']) / count\n            shopitem_price_dict[row['shop_item']] = [price, row['date_block_num'], count]\n# remove date_block_num and count in the dict to only keep [shop_item, price_month]\nfor k,v in shopitem_price_dict.items():\n    shopitem_price_dict[k] = v[0]\n\n# UT code: printout a random sample to check\nprint(len(shopitem_price_dict))\nidx = random.randint(0,len(shop_item_list))\nshop_item = shop_item_list[idx]\nprint(\"The last price of shop-item\", shop_item, \":\", shopitem_price_dict[shop_item])\nshop_item = shop_item.split('-')\ntrain_monthly_df[(train_monthly_df['shop_id']==int(shop_item[0])) &\n                 (train_monthly_df['item_id']==int(shop_item[1])) &\n                 (train_monthly_df['price_month']>0.0)].sort_values(by=['date_block_num'],ascending=[False])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the avg \"sale_cnt sequences\" of each \"item\" as default\n# In case the shop_item in test dataset does not appear in training dataset, \n# we use the \"item avg sale_cnt sequence\" as default.\n## get (item_seq_dict)\n\nitem_seq_dict = {}\nitem_seq_num_dict = {}\n# make sum\nfor k, v in data_seq_dict.items():\n    item = k.split('-')[1]\n    if item not in item_seq_dict.keys():\n        item_seq_dict[item] = v\n        item_seq_num_dict[item] = 1\n    else:\n        item_seq_dict[item] = [i+j for i, j in zip(item_seq_dict[item], v)]\n        item_seq_num_dict[item] += 1\n# make average\nfor item in item_seq_dict.keys():\n    item_seq_dict[item] = [element / item_seq_num_dict[item] for element in item_seq_dict[item]]\n\nprint(len(item_seq_dict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the \"last price\" of each \"item\" as the future price\n## get (item_price_dict)\n\nitem_price_dict = {}  # {item_id: [avg_price, current_max_date_block_num, cnt]}\n# record prices and max date_block_num of each item\nfor _, row in train_monthly_df.iterrows():\n    item_id = str(row['item_id'])\n    if item_id not in item_price_dict.keys():\n        item_price_dict[item_id] = [row['price_month'], row['date_block_num'], 1]\n    else:\n        if row['date_block_num'] > item_price_dict[item_id][1]:\n            item_price_dict[item_id] = [row['price_month'], row['date_block_num'], 1]\n        if row['date_block_num'] == item_price_dict[item_id][1]:\n            entry = item_price_dict[item_id]\n            count = entry[2] + 1\n            price = (entry[0] * entry[2] + row['price_month']) / count\n            item_price_dict[item_id] = [price, row['date_block_num'], count]\n# remove date_block_num and count in the dict to only keep [item_id, price_month]\nfor k,v in item_price_dict.items():\n    item_price_dict[k] = v[0]\n    \n# UT code: printout a random sample to check\nprint(len(item_price_dict))\nidx = random.randint(0,len(item_list))\nitem_id = str(item_list[idx])\nprint(\"The last price of item\", item_id, \":\", item_price_dict[item_id])\ntmp_df = train_monthly_df[(train_monthly_df['item_id']==int(item_id))][['date_block_num', 'price_month']]\ntmp_df = tmp_df[tmp_df['date_block_num']==tmp_df['date_block_num'].max()][['price_month']].mean()\nprint(tmp_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Preprocess\n\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import backend as K\n\n\n# parameter\nITEM_VOCAB_LEN = 1000\n\n# Scaler of price\nprice_scaler = MinMaxScaler(feature_range=(0,1))\nprice_scaler.fit([[i] for i in train_monthly_df['price_month'].tolist()])\n\n# Split X and Y\nX = []\nY = []\nfor k,v in data_seq_dict.items():\n    shop_item = k\n    static_vec = np.array([int(i) for i in k.split('-')])\n    static_vec[1] = static_vec[1] % ITEM_VOCAB_LEN\n    price_vec = price_scaler.transform([[shopitem_price_dict[k]]]).reshape((-1,))\n    static_vec = np.concatenate([static_vec, price_vec])\n    seq_vec = np.array(v).reshape((-1,1))  # (steps, 1)\n    X.append([shop_item, static_vec, seq_vec[:-1,:]])\n    Y.append(seq_vec[-1,:])\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3)\nX_train_static = np.array([x[1] for x in X_train])\nX_train_seq = np.array([x[2] for x in X_train])\nY_train = np.array(Y_train)\nX_val_static = np.array([x[1] for x in X_val])\nX_val_seq = np.array([x[2] for x in X_val])\nY_val = np.array(Y_val)\n\n# Global Parameters\nSTEPS = X_train_seq.shape[1]\n\nprint(\"Training Dataset:\")\nprint(\"\\nX_train_static:\")\nprint(X_train_static.shape)\nprint(X_train_static)\nprint(\"\\nX_train_seq:\")\nprint(X_train_seq.shape)\nprint(X_train_seq)\nprint(\"\\nY_train:\")\nprint(Y_train.shape)\nprint(Y_train)\nprint(\"\\nValidation Dataset:\")\nprint(\"\\nX_val_static:\")\nprint(X_val_static.shape)\nprint(X_val_static)\nprint(\"\\nX_val_seq:\")\nprint(X_val_seq.shape)\nprint(X_val_seq)\nprint(\"\\nY_val:\")\nprint(Y_val.shape)\nprint(Y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Initial Model, Wide&Deep\n\n# # Model Parameters\n# STEPS = X_train_seq.shape[1]\n\n# import os\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n# from math import log\n# import tensorflow as tf\n# import tensorflow_probability as tfp\n# from tensorflow import feature_column\n# from tensorflow.nn import relu\n# from tensorflow.keras import backend as K\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras import Model\n# from tensorflow.keras import Input\n# from tensorflow.keras.layers import Dense, Lambda, Concatenate, Reshape, Embedding, Conv1D, Add, Flatten, LSTM, Activation, BatchNormalization\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.metrics import mean_squared_error\n\n# # Loss\n# def root_mean_squared_error(y_true, y_pred):\n#     return K.sqrt(K.mean(K.square(y_pred - y_true))) \n\n# # Model\n# # Wide Component\n# input_static_vec = Input(name='input_static', shape = (3,))\n\n# shop_vec = Lambda(lambda x: tf.slice(x, (0,0), (-1,1)))(input_static_vec)\n# shop_emb_vec = Embedding(input_dim=60, output_dim=4, input_length=(1,))(shop_vec)\n# shop_emb_vec = Flatten()(shop_emb_vec)\n# item_vec = Lambda(lambda x: tf.slice(x, (0,1), (-1,1)))(input_static_vec)\n# item_emb_vec = Embedding(input_dim=ITEM_VOCAB_LEN, output_dim=4, input_length=(1,))(item_vec)\n# item_emb_vec = Flatten()(item_emb_vec)\n# price_vec = Lambda(lambda x: tf.slice(x, (0,2), (-1,1)))(input_static_vec)\n# wide_vec = Concatenate(axis=-1, name='Concat_wide')([shop_emb_vec, item_emb_vec, price_vec])\n\n# # Deep Component\n# input_seq_vec = Input(name='input_seq', shape = (STEPS,1))\n\n# deep_vec = LSTM(units=4, name='LSTM')(input_seq_vec)\n\n# # Fusion Layer\n# output_vec = Concatenate(axis=-1, name='Concat_fusion')([wide_vec, deep_vec])\n# output_vec = Dense(units=1, activation='relu')(output_vec)\n\n# model = Model(inputs=[input_static_vec,input_seq_vec], outputs=[output_vec])\n# model.compile(loss=root_mean_squared_error, optimizer=Adam(learning_rate=0.05))\n# model.summary()\n\n# callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001,\n#                                               verbose=1, mode='min', patience=3,\n#                                               restore_best_weights=True)]\n\n# history = model.fit(x={'input_static': X_train_static, 'input_seq': X_train_seq}, \n#                     y=Y_train,\n#                     validation_data=({'input_static':X_val_static,'input_seq':X_val_seq}, Y_val), \n#                     epochs=100, \n#                     batch_size=1024*1024,\n#                     callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Weekday Factor Model\n\n# import os\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n# from math import log\n# import tensorflow as tf\n# import tensorflow_probability as tfp\n# from tensorflow import feature_column\n# from tensorflow.nn import relu\n# from tensorflow.keras import backend as K\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras import Model\n# from tensorflow.keras import Input\n# from tensorflow.keras.layers import Dense, Lambda, Concatenate, Reshape, Embedding, Conv1D, Add, Flatten, LSTM, Activation, BatchNormalization, Multiply\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.metrics import mean_squared_error\n\n# # Loss\n# def root_mean_squared_error(y_true, y_pred):\n#     return K.sqrt(K.mean(K.square(y_pred - y_true))) \n\n# # Model\n# # Wide Component\n# input_static_vec = Input(name='input_static', shape = (3,))\n\n# shop_vec = Lambda(lambda x: tf.slice(x, (0,0), (-1,1)))(input_static_vec)\n# shop_emb_vec = Embedding(input_dim=60, output_dim=4, input_length=(1,))(shop_vec)\n# shop_emb_vec = Flatten()(shop_emb_vec)\n# item_vec = Lambda(lambda x: tf.slice(x, (0,1), (-1,1)))(input_static_vec)\n# item_emb_vec = Embedding(input_dim=ITEM_VOCAB_LEN, output_dim=4, input_length=(1,))(item_vec)\n# item_emb_vec = Flatten()(item_emb_vec)\n# price_vec = Lambda(lambda x: tf.slice(x, (0,2), (-1,1)))(input_static_vec)\n# wide_vec = Concatenate(axis=-1, name='Concat_wide')([shop_emb_vec, item_emb_vec, price_vec])\n\n# # Deep Component\n# input_seq_vec = Input(name='input_seq', shape = (STEPS,1))\n\n# deep_vec = LSTM(units=4, name='LSTM')(input_seq_vec)\n\n# # Fusion Layer\n# model_vec = Concatenate(axis=-1, name='Concat_fusion')([wide_vec, deep_vec])\n# model_vec = Dense(units=1, activation='relu')(model_vec)\n\n# # Weekday Factor Component\n# # 1. calculate the Weekday Factor\n# value_4week_vec = Lambda(lambda x: tf.slice(x, (0,STEPS-28,0), (-1,28,-1)), name='Weekday_Factor')(input_seq_vec)  # (N, 28, 1)\n# value_4week_vec = Reshape((4,7))(value_4week_vec)  # (N, 4 ,7)\n# week_mean_vec = Lambda(lambda x: tf.reduce_mean(x, axis=2, keepdims=True))(value_4week_vec)  # (N, 4, 1)\n# day_factor_vec = Lambda(lambda x: tf.math.divide_no_nan(x[0],x[1]))([value_4week_vec,week_mean_vec])  # (N, 4, 7)\n# weekday_factor_vec = Lambda(lambda x: tf.reduce_mean(x, axis=1))(day_factor_vec)  # (N, 7)\n# # 2. calculate the Base (mean of last 3 weeks)\n# value_3week_vec = Lambda(lambda x: tf.slice(x, (0,STEPS-21,0), (-1,21,-1)), name='base')(input_seq_vec)  # (N, 28, 1)\n# value_3week_vec = Reshape((21,))(value_3week_vec)  # (N, 28)\n# base_vec = Lambda(lambda x: tf.reduce_mean(x, axis=1, keepdims=True))(value_3week_vec)  # (N, 1)\n# # 3. make predicrion (weekday_factor * base)\n# weekday_factor_vec = Multiply()([weekday_factor_vec, base_vec])  # (N, 7)\n# weekday_factor_vec = Lambda(lambda x: tf.slice(x, (0,0), (-1,1)))(weekday_factor_vec)  # (N, 1)\n\n# # Output Layer\n# output_vec = Concatenate(axis=-1, name='output_Concat')([model_vec, weekday_factor_vec])\n# output_vec = Dense(units=1, activation='relu')(output_vec)\n\n# model = Model(inputs=[input_static_vec,input_seq_vec], outputs=[output_vec])\n# model.compile(loss=root_mean_squared_error, optimizer=Adam(learning_rate=0.05))\n# model.summary()\n\n# callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001,\n#                                               verbose=1, mode='min', patience=3,\n#                                               restore_best_weights=True)]\n\n# history = model.fit(x={'input_static': X_train_static, 'input_seq': X_train_seq}, \n#                     y=Y_train,\n#                     validation_data=({'input_static':X_val_static,'input_seq':X_val_seq}, Y_val), \n#                     epochs=100, \n#                     batch_size=1024*1024,\n#                     callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Fusion Fashion Model (concat/add/product)\n\n# import os\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n# from math import log\n# import tensorflow as tf\n# import tensorflow_probability as tfp\n# from tensorflow import feature_column\n# from tensorflow.nn import relu\n# from tensorflow.keras import backend as K\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras import Model\n# from tensorflow.keras import Input\n# from tensorflow.keras.layers import Dense, Lambda, Concatenate, Reshape, Embedding, Conv1D, Add, Flatten, LSTM, Activation, BatchNormalization, Multiply\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.metrics import mean_squared_error\n\n# # Loss\n# def root_mean_squared_error(y_true, y_pred):\n#     return K.sqrt(K.mean(K.square(y_pred - y_true))) \n\n# # Model\n# # Wide Component\n# input_static_vec = Input(name='input_static', shape = (3,))\n\n# shop_vec = Lambda(lambda x: tf.slice(x, (0,0), (-1,1)))(input_static_vec)\n# shop_emb_vec = Embedding(input_dim=60, output_dim=4, input_length=(1,))(shop_vec)\n# shop_emb_vec = Flatten()(shop_emb_vec)\n# item_vec = Lambda(lambda x: tf.slice(x, (0,1), (-1,1)))(input_static_vec)\n# item_emb_vec = Embedding(input_dim=ITEM_VOCAB_LEN, output_dim=4, input_length=(1,))(item_vec)\n# item_emb_vec = Flatten()(item_emb_vec)\n# price_vec = Lambda(lambda x: tf.slice(x, (0,2), (-1,1)))(input_static_vec)\n# wide_vec = Concatenate(axis=-1, name='Concat_wide')([shop_emb_vec, item_emb_vec, price_vec])  # (N, 9)\n\n# # Deep Component\n# input_seq_vec = Input(name='input_seq', shape = (STEPS,1))\n\n# deep_vec = LSTM(units=9, name='LSTM')(input_seq_vec)  # (N, 9)\n\n# # Fusion Layer\n# # output_vec = Concatenate(axis=-1, name='Concat_fusion')([wide_vec, deep_vec])\n# # output_vec = Add(name='Concat_fusion')([wide_vec, deep_vec])\n# # output_vec = Multiply(name='Concat_fusion')([wide_vec, deep_vec])\n# output_vec = Dense(units=1, activation='relu')(output_vec)\n\n# model = Model(inputs=[input_static_vec,input_seq_vec], outputs=[output_vec])\n# model.compile(loss=root_mean_squared_error, optimizer=Adam(learning_rate=0.05))\n# model.summary()\n\n# callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001,\n#                                               verbose=1, mode='min', patience=3,\n#                                               restore_best_weights=True)]\n\n# history = model.fit(x={'input_static': X_train_static, 'input_seq': X_train_seq}, \n#                     y=Y_train,\n#                     validation_data=({'input_static':X_val_static,'input_seq':X_val_seq}, Y_val), \n#                     epochs=100, \n#                     batch_size=1024*1024,\n#                     callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, to_file='model_graph.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['loss'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_loss'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare Test dataset\n\ntest_df = pd.read_csv('/kaggle/input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')\ntest_df['shop_item'] = test_df['shop_id'].astype('string') + '-' + test_df['item_id'].astype('string')\n\nX_test_static = []\nX_test_seq = []\nfor _, row in test_df.iterrows():\n    shop_item = row['shop_item']\n    shop_id = str(row['shop_id'])\n    item_id = str(row['item_id'])\n    \n    # get sale_cnt_seq\n    if shop_item in data_seq_dict.keys():\n        sale_cnt_seq = data_seq_dict[shop_item][1:]\n    else:\n        if item_id in item_seq_dict.keys():\n            sale_cnt_seq = item_seq_dict[item_id][1:]\n        else:\n            sale_cnt_seq = [0.0 for i in range(0,STEPS)]\n    \n    # get price\n    if shop_item in shopitem_price_dict.keys():\n        price = shopitem_price_dict[shop_item]\n    else:\n        if item_id in item_price_dict.keys():\n            price = item_price_dict[item_id]\n        else:\n            price = 0.0\n    \n    # generate the sample\n    static_vec = np.array([int(shop_id), int(item_id) % ITEM_VOCAB_LEN])\n    price_vec = price_scaler.transform([[price]]).reshape((-1,))\n    static_vec = np.concatenate([static_vec, price_vec])\n    seq_vec = np.array(sale_cnt_seq).reshape((-1,1))  # (steps, 1)\n    X_test_static.append(static_vec)\n    X_test_seq.append(seq_vec)\nX_test_static = np.array(X_test_static)\nX_test_seq = np.array(X_test_seq)\n\n\nprint('X_test_static:')\nprint(X_test_static.shape)\nprint(X_test_static)\nprint('\\nX_test_seq:')\nprint(X_test_seq.shape)\nprint(X_test_seq)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict({'input_static':X_test_static, 'input_seq':X_test_seq})\nprint(pred.shape)\nprint(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Weekday Factor Method (Best Solver Poster)\n# # non-Learnable model\n\n# from scipy.stats import norm\n\n# data = X_test_seq.squeeze()\n# # Preprocess: recover outliers\n# for i in range(0,data.shape[0]):\n#     for j in range(13,data.shape[1]):\n#         mean, stddev = norm.fit(data[i,j-13:j+1])\n#         if data[i,j] > mean + 2 * stddev:\n#             data[i,j] = mean + 2 * stddev\n#         if data[i,j] < mean - 2 * stddev:\n#             data[i,j] = mean - 2 * stddev\n\n# # 1. calculate the Weekday Factor\n# data_last_4_week = data[:,5:]  # (214200, 28)\n# day_factor_list = []\n# for i in range(0,4):\n#     day_value = data_last_4_week[:,i*7:(i+1)*7]  # (214200, 7)\n#     week_mean = np.mean(day_value, axis=1, keepdims=True)  # (214200, 1)\n#     day_factor = np.divide(day_value, week_mean, out=np.zeros_like(day_value), where=week_mean!=0.)\n#     day_factor_list.append(day_factor)\n# day_factors = np.stack(day_factor_list, axis=2)  # (214200, 7, 4)\n# weekday_factor = np.mean(day_factors, axis=2)  # (214200, 7)\n\n# # 2. calculate the Base (mean of last 3 weeks)\n# data_last_3_week = data[:,12:]  # (214200, 21)\n# base = np.mean(data_last_3_week, axis=1, keepdims=True)  # (214200, 1)\n\n# # 3. make predicrion (weekday_factor * base)\n# pred = weekday_factor * base  # (214200, 7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# recover the prediction (de-normalized)\nresults = pred[:,0]\nresults[results<0.] = 0.\nresults[0:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame(results, columns=['item_cnt_month'])\nsubmission_df.index.name = 'ID'\nsubmission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('/kaggle/working/submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}